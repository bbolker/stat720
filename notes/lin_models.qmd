---
title: "Review of linear models"
bibliography: "../stats720.bib"
date: today
date-format: "D MMM YYYY"
csl: apa.csl
format:
  pdf:
    mainfont: TeX Gyre Pagella
    include-in-header:
     - text: \usepackage{marginnote}

---

::: {.content-hidden}
$$
{{< include mathsymbols.tex >}}
$$
:::

<!-- typically renders in docs/ dir  -->

## Basics

* assume $\y \sim \textrm{Normal}(\X \bbeta, \sigma)$^[Notation-abuse warning ...]
* $\X$ is the *model matrix*, can be anything we want it to be
* the *Gauss-Markov theorem* ([Wikipedia](https://en.wikipedia.org/wiki/Gauss%E2%80%93Markov_theorem)) makes weaker assumptions: $\y = \X \bbeta + \beps$; as long as $\beps$ is mean-zero, homoscedastic with finite variance, and uncorrelated ... then the OLS solution
$$
\hat{\bbeta} = (\t{\X} \X)^{-1} \t{\X} \y
$$
is the BLUE (or MVUE).
* we'll embrace the assumptions (which are needed for inference!)

## Computation

* matrix decompositions (QR with pivoting)
* big problems: `biglm`, `speedglm`, `RcppEigen::fastLm`
   * optimized BLAS, kernel trick, etc.
   * memory vs speed vs robustness ...
   * $p$ vs. $n$ vs. many-small-regressions vs. ...

## Inference

* $\sigma^2$ (residual variance) is $\textrm{RSS}/(n-p)$
* The covariance matrix is $\sigma^2 (\t{\X} \X)^{-1}$. 
* Individual coefficients are $t$-distributed
* Linear combinations of coefficients are $F$-distributed
* Wald and likelihood ratio test comparisons are equivalent  
(but need to be careful about marginality)

## Model matrices

* model definition converted to $\X$ before we start
* **input variables** vs **predictor variables** (@schielzethSimple2010, @gelmanData2006, [CV](https://stats.stackexchange.com/questions/511455/terminology-for-raw-vs-derived-predictor-variables))
   * transformations
   * encoding of categorical variables: **contrasts**
   * interactions
   * basis expansions (e.g. polynomials)

## Wilkinson-Rogers formulas 

- @wilkinsonSymbolic1973a, updated by @chambersStatistical1991 [ch. 2]
- operators: `+`, `*`, `:`, `/`, `-`, `^`
- `I()`

## Contrasts

## Marginality

* @venablesExegeses1998
* 'type (X) sums of squares'
* scaling and centering [@schielzethSimple2010]


## Downstream methods

* prediction, effects plots
* uncertainty of predictions
* `emmeans`, `marginaleffects`, `effects`, `sjPlot` ...
* `tidy()`, `performance`, `insight`, etc. ...

## Diagnostics

* linearity, 
* base R: `stats::plot.lm()`
* `performance::check_model()`
* `DHARMa` (`simulateResiduals(., plot = TRUE)`)

## References


::: {#refs}
:::
